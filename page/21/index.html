<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/page/21/index.html">
<meta property="og:site_name" content="Hexo">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hexo">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-scrapy爬虫出现connection-refused的一个可能原因" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/01/15/scrapy爬虫出现connection-refused的一个可能原因/" class="article-date">
  <time datetime="2015-01-15T01:30:28.000Z" itemprop="datePublished">2015-01-15</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/scrapy/">scrapy</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/01/15/scrapy爬虫出现connection-refused的一个可能原因/">scrapy爬虫出现connection refused的一个可能原因</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>下载了别人的一个爬虫，跑的时候发现会出现connection refused的错误</p>
<pre><code>Connection was refused by other side: 111: Connection refused.
</code></pre><p>有时候还能继续跑，但是不一会儿就停了，代码很简单，至少scrapy.py不会有问题，哪有问题的应该就是setting了</p>
<p>看了一下setting文件，里面DOWNLOADER_MIDDLEWARES启用了两个自定义的中间件：<code>CustomHttpProxyMiddleware</code>和<code>CustomUserAgentMiddleware</code>，其中<code>CustomUserAgentMiddleware</code>是用来模拟浏览器登陆的，<code>CustomHttpProxyMiddleware</code>则是防止网站对ip限制，使用代理进行抓取。不妨分别将二者注释掉再跑看看。最终发现果然是<code>CustomHttpProxyMiddleware</code>出了问题，那proxy.py里面是什么呢？</p>
<pre><code>PROXIES = [
{&quot;ip_port&quot;: &quot;127.0.0.1:8087&quot;},
]
</code></pre><p>127.0.0.1是本机的环回地址，同时也是goagent的代理ip，作者本意应该是使用goagent来做ip轮换的工作，但是没那么简单啊，你的goagent没有配置呢，所以用到127.0.0.1的时候网站自然不让你访问了</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/01/15/scrapy爬虫出现connection-refused的一个可能原因/" data-id="cj64upq2p0082lraer0r4k3nk" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/">python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/scrapy/">scrapy</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Scrapy的架构" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/01/14/Scrapy的架构/" class="article-date">
  <time datetime="2015-01-14T02:46:23.000Z" itemprop="datePublished">2015-01-14</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/scrapy/">scrapy</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/01/14/Scrapy的架构/">scrapy的架构</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>下面是scrapy的架构图<br><img src="/img/scrapy_architecture.png" alt="scrapy architecture"></p>
<p>##一. 组件</p>
<ol>
<li><code>Scrapy Engine（Scrapy引擎）</code>：Scrapy引擎是用来控制整个系统的数据处理流程，并进行事务处理的触发。更多的详细内容可以看下面的数据处理流程。</li>
<li><code>Scheduler（调度）</code>：调度程序从Scrapy引擎接受请求并排序列入队列，并在Scrapy引擎发出请求后返还给他们。</li>
<li><code>Downloader（下载器）</code>：下载器的主要职责是抓取网页并将网页内容返还给蜘蛛( Spiders)。</li>
<li><code>Spiders（蜘蛛）</code>：蜘蛛是有Scrapy用户自己定义用来解析网页并抓取制定URL返回的内容的类，每个蜘蛛都能处理一个域名或一组域名。换句话说就是用来定义特定网站的抓取和解析规则。蜘蛛的整个抓取流程（周期）是这样的：<ol>
<li>首先获取第一个URL的初始请求，当请求返回后调取一个回调函数。第一个请求是通过调用start_requests()方法。该方法默认从start_urls中的Url中生成请求，并执行解析来调用回调函数。</li>
<li>在回调函数中，你可以解析网页响应并返回项目对象和请求对象或两者的迭代。这些请求也将包含一个回调，然后被Scrapy下载，然后有指定的回调处理。</li>
<li>在回调函数中，你解析网站的内容，同程使用的是Xpath选择器（但是你也可以使用BeautifuSoup, lxml或其他任何你喜欢的程序），并生成解析的数据项。</li>
<li>最后，从蜘蛛返回的项目通常会进驻到项目管道。</li>
</ol>
</li>
<li><p><code>Item Pipeline（项目管道）</code>：项目管道的主要责任是负责处理有蜘蛛从网页中抽取的项目，他的主要任务是清晰、验证和存储数据。当页面被蜘蛛解析后，将被发送到项目管道，并经过几个特定的次序处理数据。每个项目管道的组件都是有一个简单的方法组成的Python类。他们获取了项目并执行他们的方法，同时他们还需要确定的是是否需要在项目管道中继续执行下一步或是直接丢弃掉不处理。项目管道通常执行的过程有：</p>
<ol>
<li>清洗HTML数据</li>
<li>验证解析到的数据（检查项目是否包含必要的字段）</li>
<li>检查是否是重复数据（如果重复就删除）</li>
<li>将解析到的数据存储到数据库中</li>
</ol>
</li>
<li><p><code>Downloader middlewares（下载器中间件）</code>：下载中间件是位于Scrapy引擎和下载器之间的钩子框架，主要是处理Scrapy引擎与下载器之间的请求及响应。它提供了一个自定义的代码的方式来拓展Scrapy的功能。下载中间器是一个处理请求和响应的钩子框架。他是轻量级的，对Scrapy尽享全局控制的底层的系统。</p>
</li>
<li><code>Spider middlewares（蜘蛛中间件）</code>:蜘蛛中间件是介于Scrapy引擎和蜘蛛之间的钩子框架，主要工作是处理蜘蛛的响应输入和请求输出。它提供一个自定义代码的方式来拓展Scrapy的功能。蛛中间件是一个挂接到Scrapy的蜘蛛处理机制的框架，你可以插入自定义的代码来处理发送给蜘蛛的请求和返回蜘蛛获取的响应内容和项目。</li>
<li><code>Scheduler middlewares（调度中间件）</code>:调度中间件是介于Scrapy引擎和调度之间的中间件，主要工作是处从Scrapy引擎发送到调度的请求和响应。他提供了一个自定义的代码来拓展Scrapy的功能</li>
</ol>
<p>##二. 数据处理流程</p>
<ol>
<li>Scrapy的整个数据处理流程有Scrapy引擎进行控制，其主要的运行方式为：</li>
<li>引擎打开一个域名，时蜘蛛处理这个域名，并让蜘蛛获取第一个爬取的URL。</li>
<li>引擎从蜘蛛那获取第一个需要爬取的URL，然后作为请求在调度中进行调度。</li>
<li>引擎从调度那获取接下来进行爬取的页面。</li>
<li>调度将下一个爬取的URL返回给引擎，引擎将他们通过下载中间件发送到下载器。</li>
<li>当网页被下载器下载完成以后，响应内容通过下载中间件被发送到引擎。</li>
<li>引擎收到下载器的响应并将它通过蜘蛛中间件发送到蜘蛛进行处理。</li>
<li>蜘蛛处理响应并返回爬取到的项目，然后给引擎发送新的请求。</li>
<li>引擎将抓取到的项目项目管道，并向调度发送请求。</li>
<li>系统重复第二部后面的操作，直到调度中没有请求，然后断开引擎与域之间的联系。</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/01/14/Scrapy的架构/" data-id="cj64uppxk001ylraen2okryw2" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/">python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/scrapy/">scrapy</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-scrapy防止被ban的策略" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/01/14/scrapy防止被ban的策略/" class="article-date">
  <time datetime="2015-01-14T02:37:02.000Z" itemprop="datePublished">2015-01-14</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/scrapy/">scrapy</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/01/14/scrapy防止被ban的策略/">scrapy防止被ban的策略</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>转载自<a href="http://blog.csdn.net/u012150179/article/details/35774323" target="_blank" rel="external">这里</a></p>
<p>#1. 设置download_delay</p>
<p>   他的作用主要是设置下载的等待时间，大规模集中的访问对服务器的影响最大，相当于短时间中增大服务器负载。下载等待时间长，不能满足短时间大规模抓取的要求，太短则大大增加了被ban的几率。如果你的爬虫工作的好好的，突然掉线了，并且得到了类似下面的错误：</p>
<pre><code>twisted.internet.error.ConnectionRefusedError
</code></pre><p>不妨试着将download_delay设置的大一点。</p>
<p>使用注意：</p>
<p>download_delay可以设置在settings.py中，也可以在spider中设置</p>
<p>#2. 禁止cookies</p>
<p>所谓cookies，是指某些网站为了辨别用户身份而储存在用户本地终端（Client Side）上的数据（通常经过加密），禁止cookies也就防止了可能使用cookies识别爬虫轨迹的网站得逞。</p>
<p>使用：</p>
<p>在settings.py中设置COOKIES_ENABLES=False。也就是不启用cookies middleware，不向web server发送cookies</p>
<p>#3. 使用user agent池<br>所谓的user agent，是指包含浏览器信息、操作系统信息等的一个字符串，也称之为一种特殊的网络协议。服务器通过它判断当前访问对象是浏览器、邮件客户端还是网络爬虫。在request.headers可以查看user agent。如下，使用scrapy shell查看：</p>
<pre><code>scrapy shell http://michaelyou.github.io
</code></pre><p>输出request.headers可以得到如下信息</p>
<pre><code>In [1]: request.headers
Out[1]: 
{&apos;Accept&apos;: &apos;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&apos;,
&apos;Accept-Encoding&apos;: &apos;gzip,deflate&apos;,
&apos;Accept-Language&apos;: &apos;en&apos;,
&apos;User-Agent&apos;: &apos;Scrapy/0.24.4 (+http://scrapy.org)&apos;}
</code></pre><p>由此得到,scrapy本身是使用Scrapy/0.24.4来表明自己身份的。这也就暴露了自己是爬虫的信息。解决方法如下：</p>
<p>首先编写自己的UserAgentMiddle中间件，在spider目录下新建rotate_useragent.py,代码如下：</p>
<pre><code># -*-coding:utf-8-*-

from scrapy import log

&quot;&quot;&quot;避免被ban策略之一：使用useragent池。

使用注意：需在settings.py中进行相应的设置。
&quot;&quot;&quot;

import random
from scrapy.contrib.downloadermiddleware.useragent import UserAgentMiddleware

class RotateUserAgentMiddleware(UserAgentMiddleware):

    def __init__(self, user_agent=&apos;&apos;):
        self.user_agent = user_agent

    def process_request(self, request, spider):
        ua = random.choice(self.user_agent_list)
        if ua:
            #显示当前使用的useragent
            print &quot;********Current UserAgent:%s************&quot; %ua

            #记录
            log.msg(&apos;Current UserAgent: &apos;+ua, level=&apos;INFO&apos;)
            request.headers.setdefault(&apos;User-Agent&apos;, ua)

    #the default user_agent_list composes chrome,I E,firefox,Mozilla,opera,netscape
    #for more user agent strings,you can find it in http://www.useragentstring.com/pages/useragentstring.php
    user_agent_list = [\
        &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 &quot;
        &quot;(KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1&quot;,
        &quot;Mozilla/5.0 (X11; CrOS i686 2268.111.0) AppleWebKit/536.11 &quot;
        &quot;(KHTML, like Gecko) Chrome/20.0.1132.57 Safari/536.11&quot;,
        &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.6 &quot;
        &quot;(KHTML, like Gecko) Chrome/20.0.1092.0 Safari/536.6&quot;,
        &quot;Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.6 &quot;
        &quot;(KHTML, like Gecko) Chrome/20.0.1090.0 Safari/536.6&quot;,
        &quot;Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.1 &quot;
        &quot;(KHTML, like Gecko) Chrome/19.77.34.5 Safari/537.1&quot;,
        &quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/536.5 &quot;
        &quot;(KHTML, like Gecko) Chrome/19.0.1084.9 Safari/536.5&quot;,
        &quot;Mozilla/5.0 (Windows NT 6.0) AppleWebKit/536.5 &quot;
        &quot;(KHTML, like Gecko) Chrome/19.0.1084.36 Safari/536.5&quot;,
        &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 &quot;
        &quot;(KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3&quot;,
        &quot;Mozilla/5.0 (Windows NT 5.1) AppleWebKit/536.3 &quot;
        &quot;(KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3&quot;,
        &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_0) AppleWebKit/536.3 &quot;
        &quot;(KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3&quot;,
        &quot;Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 &quot;
        &quot;(KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3&quot;,
        &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 &quot;
        &quot;(KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3&quot;,
        &quot;Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 &quot;
        &quot;(KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3&quot;,
        &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 &quot;
        &quot;(KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3&quot;,
        &quot;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 &quot;
        &quot;(KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3&quot;,
        &quot;Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 &quot;
        &quot;(KHTML, like Gecko) Chrome/19.0.1061.0 Safari/536.3&quot;,
        &quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.24 &quot;
        &quot;(KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24&quot;,
        &quot;Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/535.24 &quot;
        &quot;(KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24&quot;
       ]
</code></pre><p>建立user agent池（user_agent_list）并在每次发送request之前从agent池中随机选取一项设置request的User_Agent。编写的UserAgent中间件的基类为UserAgentMiddle。</p>
<p>除此之外，要在settings.py(配置文件)中禁用默认的useragent并启用重新实现的User Agent。配置方法如下：</p>
<p>#取消默认的useragent,使用新的useragent<br>    DOWNLOADER_MIDDLEWARES = {<br>            ‘scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware’ : None,<br>            ‘CSDNBlogCrawlSpider.spiders.rotate_useragent.RotateUserAgentMiddleware’ :400<br>        }</p>
<p>#4. 使用IP池<br>web server应对爬虫的策略之一就是直接将你的IP或者是整个IP段都封掉禁止访问，这时候，当IP封掉后，转换到其他的IP继续访问即可。</p>
<p>可以使用Scrapy+Tor+polipo</p>
<p>配置方法与使用教程请点<a href="http://pkmishra.github.io/blog/2013/03/18/how-to-run-scrapy-with-TOR-and-multiple-browser-agents-part-1-mac/" target="_blank" rel="external">这里</a>。</p>
<p>#5. 分布式爬取<br>有时间再补充</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/01/14/scrapy防止被ban的策略/" data-id="cj64upq2t0088lrae2visejyq" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/">python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/scrapy/">scrapy</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-一些常用的shell和vim命令" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/01/14/一些常用的shell和vim命令/" class="article-date">
  <time datetime="2015-01-14T01:04:29.000Z" itemprop="datePublished">2015-01-14</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/linux/">linux</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/01/14/一些常用的shell和vim命令/">一些常用的shell和vim命令</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <ul>
<li><p>删除一个目录下所有某个格式的文件</p>
<pre><code>find . -name &quot;*.pyc&quot; -type f -print -exec rm -rf {} \;
find . -name &quot;*.pyc&quot; -type f -print0 | xargs -0 rm -f
//-print0选项将&apos;\0&apos;作为find输出的分隔符
//xargs -0将&apos;\0&apos;作为输入定界符
</code></pre></li>
<li><p>把文件夹内所有文件中的一个字符串替换成另外一个字符串</p>
<pre><code>sed -i &quot;s/descritpion/scription/g&quot; `grep descritpion -rl .`
//将文件夹所有文件中的descritpion替换成scription
</code></pre></li>
<li><p>统计代码行数</p>
<pre><code>find -type f -name &apos;*.c&apos; -print0 | xargs -0 wc -l
//此命令可以找到路径下所有c文件，并统计行数（双引号必不可少）
//wc -l 统计一个文件的行数
</code></pre></li>
<li><p>vim的全文替换</p>
<pre><code>在：下，命令1,$s/he/you/g
将文件中的he替换成you，其中$表示到文件最后一行
</code></pre></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/01/14/一些常用的shell和vim命令/" data-id="cj64upq340094lraewhexutym" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/linux/">linux</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/shell/">shell</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/vim/">vim</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-在scrapy提供的shell中测试xpath" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/01/13/在scrapy提供的shell中测试xpath/" class="article-date">
  <time datetime="2015-01-13T13:33:06.000Z" itemprop="datePublished">2015-01-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/scrapy/">scrapy</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/01/13/在scrapy提供的shell中测试xpath/">在scrapy提供的shell中测试xpath</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>scrapy的Rule定义了从html中取url的规则，但是这些url是被自动提取，也无法打印，如果xpath有误很难调试。下面提供一种方法可以在scrapy的shell中测试LinkExtractor的xpath的正确性</p>
<pre><code>1.scrapy shell &apos;url&apos;
2.from scrapy.contrib.linkextractors import LinkExtractor
3.item= LinkExtractor(allow=(&apos;***&apos;),restrict_xpaths=(&apos;***&apos;)).extract_links(response)
4.for i in item:
      print i.text
</code></pre><p>这样就可以打印出从response中提取的url了，注意得到的item是一个list，所以要循环遍历</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/01/13/在scrapy提供的shell中测试xpath/" data-id="cj64upq4l00b1lrae3qg4y5mb" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/">python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/scrapy/">scrapy</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-urllib2和scrapy的302redirect错误" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/01/13/urllib2和scrapy的302redirect错误/" class="article-date">
  <time datetime="2015-01-13T07:24:18.000Z" itemprop="datePublished">2015-01-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/scrapy/">scrapy</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/01/13/urllib2和scrapy的302redirect错误/">urllib2和scrapy的302redirect错误</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>今天用爬虫爬csdn的blog的时候，发现会产生302重定向的问题，并且，重定向的url仍然是原来的url，这样就会产生一个infinite loop，让爬虫无法工作。下面说一下解决的方法：</p>
<p>##urllib2的错误</p>
<pre><code>代码：
#encoding=utf-8

import urllib
import urllib2

response = urllib2.urlopen(url)
print response.read()
</code></pre><p>运行上面的代码会产生下面的错误，爬虫会退出</p>
<p>######urllib2.HTTPError: HTTP Error 302: The HTTP server returned a redirect error that would lead to an infinite loop.#The last 30x error message was:Moved Temporarily####<br>避免这个问题的方法就是在代码中加入对cookie的处理，下面是改正后的代码：</p>
<pre><code>代码：
#encoding=utf-8

import urllib
import cookielib, urllib2

cj = cookielib.CookieJar()
opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cj))
headers = {
    &apos;User-Agent&apos;:&apos;Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6&apos;
    }
request = urllib2.Request(
    url = &apos;************&apos;,
    headers = headers
    )
response = opener.open(request)
print response.read()
</code></pre><p>代码中同时修改了headers来模仿浏览器登陆，如果只cookie处理部分的代码会出现403forbidden的错误。</p>
<p>##使用scrapy的修改方法<br>其实使用scrapy本不应该出现这个问题的，因为scrapy自带对cookie的处理，那这个问题是如何产生的呢？<br>scrapy中文文档中的<a href="http://scrapy-chs.readthedocs.org/zh_CN/latest/topics/practices.html?highlight=ban#ban" target="_blank" rel="external">避免被禁止(ban)</a>这一节讲过</p>
<blockquote>
<p>禁止cookies(参考 COOKIES_ENABLED)，有些站点会使用cookies来发现爬虫的轨迹</p>
</blockquote>
<p>所以在一些代码中会采取这个策略，在setting.py中将COOKIES_ENABLED设置为False，也就是禁止scrapy来处理cookie，这在大部分网站下可能都是可用的，但很难说会遇到今天这样的问题，必须要处理cookie，说到这里大家应该都明白了，正确的处理方法就是在setting.py中将COOKIES_ENABLED的值改为True，即：</p>
<pre><code>COOKIES_ENABLED = True
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/01/13/urllib2和scrapy的302redirect错误/" data-id="cj64upq2z008tlrae6e2l07uw" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/">python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/scrapy/">scrapy</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/urllib/">urllib</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <a class="extend prev" rel="prev" href="/page/20/">&laquo; __('prev')</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/19/">19</a><a class="page-number" href="/page/20/">20</a><span class="page-number current">21</span>
  </nav>
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Django/">Django</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/JavaScript/">JavaScript</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/TCP-IP/">TCP/IP</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/c/">c</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/git/">git</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/http/">http</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/jQuery/">jQuery</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/linux/">linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/mac/">mac</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/openstack/">openstack</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/scrapy/">scrapy</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/twisted/">twisted</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/unix网络编程/">unix网络编程</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/vim/">vim</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/web/">web</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库/">数据库</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法/">算法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/编译原理/">编译原理</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/网络/">网络</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/长知识/">长知识</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/面试/">面试</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/bash/">bash</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/c/">c</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/http/">http</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/jQuery/">jQuery</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/">linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mac/">mac</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mongodb/">mongodb</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/openstack/">openstack</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scrapy/">scrapy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/shell/">shell</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/socket/">socket</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ssh/">ssh</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tcp-ip/">tcp/ip</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ubuntu/">ubuntu</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/unicode/">unicode</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/urllib/">urllib</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vim/">vim</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/异步编程/">异步编程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/排序/">排序</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/操作系统/">操作系统</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据库/">数据库</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据结构/">数据结构</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/正则/">正则</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/算法/">算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/网络基础/">网络基础</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/面试/">面试</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/bash/" style="font-size: 10px;">bash</a> <a href="/tags/c/" style="font-size: 19px;">c</a> <a href="/tags/http/" style="font-size: 14px;">http</a> <a href="/tags/jQuery/" style="font-size: 10px;">jQuery</a> <a href="/tags/linux/" style="font-size: 17px;">linux</a> <a href="/tags/mac/" style="font-size: 11px;">mac</a> <a href="/tags/mongodb/" style="font-size: 10px;">mongodb</a> <a href="/tags/openstack/" style="font-size: 10px;">openstack</a> <a href="/tags/python/" style="font-size: 20px;">python</a> <a href="/tags/scrapy/" style="font-size: 16px;">scrapy</a> <a href="/tags/shell/" style="font-size: 13px;">shell</a> <a href="/tags/socket/" style="font-size: 11px;">socket</a> <a href="/tags/ssh/" style="font-size: 10px;">ssh</a> <a href="/tags/tcp-ip/" style="font-size: 13px;">tcp/ip</a> <a href="/tags/ubuntu/" style="font-size: 10px;">ubuntu</a> <a href="/tags/unicode/" style="font-size: 10px;">unicode</a> <a href="/tags/urllib/" style="font-size: 10px;">urllib</a> <a href="/tags/vim/" style="font-size: 10px;">vim</a> <a href="/tags/异步编程/" style="font-size: 18px;">异步编程</a> <a href="/tags/排序/" style="font-size: 10px;">排序</a> <a href="/tags/操作系统/" style="font-size: 11px;">操作系统</a> <a href="/tags/数据库/" style="font-size: 12px;">数据库</a> <a href="/tags/数据结构/" style="font-size: 10px;">数据结构</a> <a href="/tags/正则/" style="font-size: 10px;">正则</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a> <a href="/tags/网络基础/" style="font-size: 10px;">网络基础</a> <a href="/tags/面试/" style="font-size: 10px;">面试</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">December 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">June 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">May 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">January 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">November 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/08/">August 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/07/">July 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/06/">June 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/05/">May 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/04/">April 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/03/">March 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/02/">February 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/01/">January 2015</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/12/19/Django外键赋值/">Django外键赋值</a>
          </li>
        
          <li>
            <a href="/2016/11/03/Django-redis如何支持存取整型和布尔值/">Django-redis如何支持存取整型和布尔值</a>
          </li>
        
          <li>
            <a href="/2016/10/17/Django-model去掉unique_together报错/">Django model去掉unique_together报错</a>
          </li>
        
          <li>
            <a href="/2016/07/10/python-string-intern/">python_string_intern</a>
          </li>
        
          <li>
            <a href="/2016/06/05/Python-面试题集锦-转载/">Python 面试题集锦[转载]</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>